# Databricks notebook source
# MAGIC %md
# MAGIC # Runbook Generator Notebook
# MAGIC Generates the final runbook markdown using a template-based approach (reliable for free tier).

# COMMAND ----------

dbutils.library.restartPython()

# COMMAND ----------

import os
import pandas as pd
import datetime
import uuid

# COMMAND ----------

dbutils.widgets.text("output_path", "/dbfs/tmp/ps_ai_runbook_gen/runbooks")
dbutils.widgets.text("model_type", "distilbert-base-uncased")
dbutils.widgets.text("input_data", "") # New widget for direct JSON input

output_path = dbutils.widgets.get("output_path")
model_type = dbutils.widgets.get("model_type")
input_data_json = dbutils.widgets.get("input_data")

# COMMAND ----------

import json

# Load Data (Priority: Direct Input > Gold Table)
docs = []

if input_data_json and input_data_json.strip():
    print("Using direct input data (Bypassing DBFS/Gold Table)")
    try:
        input_files = json.loads(input_data_json)
        # Convert to expected format for the rest of the notebook
        for filename, content in input_files.items():
            # Simple entity extraction simulation for direct input
            entities = []
            if "TECH:" in content:
                # Extract tech from content if simulated
                pass 
            
            # For now, we just pass the raw content. 
            # In a real app, we'd run the NLP here or expect pre-processed entities.
            # To make the existing logic work, we'll simulate some entities based on keywords
            if "hadoop" in content.lower(): entities.append("TECH: Hadoop")
            if "hive" in content.lower(): entities.append("TECH: Hive")
            if "spark" in content.lower(): entities.append("TECH: Spark")
            if "databricks" in content.lower(): entities.append("TECH: Databricks")
            if "mlflow" in content.lower(): entities.append("TECH: MLflow")
            if "2024" in content: entities.append("DATE: 2024-01-01") # Mock date
            
            docs.append({
                "path": f"dbfs:/uploads/{filename}", 
                "content": content,
                "entities": entities
            })
        print(f"Loaded {len(docs)} documents from direct input")
    except Exception as e:
        print(f"Error parsing input_data: {e}")
        dbutils.notebook.exit(f"FAILED: Error parsing input data - {str(e)}")

else:
    # Fallback to loading Gold Data (Original Logic)
    try:
        df = spark.table("gold_engagement_vectors")
        docs = df.collect()
        print(f"Loaded {len(docs)} documents from Gold Table")
    except Exception as e:
        print(f"Error loading gold table: {e}")
        # If we are here, it means no input data AND no gold table. 
        # For Community Edition, this is likely fatal if we expected DBFS to work.
        # But we can return a helpful error.
        dbutils.notebook.exit("FAILED: No input data provided and could not load gold table")

# COMMAND ----------

# Extract aggregated insights
all_entities = []
tech_stack = set()
risks = []
dates = []

for row in docs:
    if row['entities']:
        for entity in row['entities']:
            all_entities.append(entity)
            if "TECH:" in entity:
                tech_stack.add(entity.replace("TECH: ", ""))
            if "DATE:" in entity:
                dates.append(entity.replace("DATE: ", ""))

# Simple "AI" Logic for Executive Summary
doc_count = len(docs)
tech_summary = ", ".join(list(tech_stack)[:5]) if tech_stack else "Standard Databricks Stack"

executive_summary = f"""
This engagement involves the analysis of {doc_count} key documents. 
The primary technology stack identified includes **{tech_summary}**. 
The engagement is currently in the planning/execution phase with key milestones identified in the attached schedule.
"""

# COMMAND ----------

# Generate Professional Runbook Markdown
markdown_output = f"""# üìò Professional Services Engagement Runbook
**Generated by:** PS AI Runbook Generator ({model_type})  
**Date:** {datetime.datetime.now().strftime("%Y-%m-%d %H:%M")}  
**Status:** DRAFT

---

## 1. Executive Summary
{executive_summary}

## 2. Engagement Scope
The following documents were ingested and analyzed to create this runbook:
"""

for row in docs:
    filename = row['path'].split('/')[-1]
    markdown_output += f"- üìÑ **{filename}**\n"

markdown_output += """
## 3. Technical Architecture
Based on the analysis, the following core components are involved:
"""

if tech_stack:
    for tech in tech_stack:
        markdown_output += f"- ‚úÖ {tech}\n"
else:
    markdown_output += "- No specific technologies detected in current document set.\n"

markdown_output += """
## 4. Identified Risks & Assumptions
- **Risk:** Data quality dependencies for ingested sources.
- **Risk:** Timeline constraints based on identified dates.
- **Assumption:** All provided documents are current and approved.

## 5. Next Steps
1. Review and validate the extracted technical stack.
2. Confirm key dates found in documents:
"""

if dates:
    for date in dates:
        markdown_output += f"   - üìÖ {date}\n"
else:
    markdown_output += "   - No specific dates extracted.\n"

markdown_output += """
---
*Generated via Databricks PS AI Tooling Prototype*
"""

# COMMAND ----------

# Return output via dbutils.notebook.exit (Works for Community Edition)
# DBFS write is optional and skipped if using direct input to avoid permission issues

if input_data_json and input_data_json.strip():
    # Direct input mode: Skip DBFS write, only return via notebook.exit
    print(f"‚úÖ Runbook generated (length: {len(markdown_output)} chars)")
    print("Returning runbook via notebook.exit (Direct Input Mode - DBFS write skipped)")
    dbutils.notebook.exit(markdown_output)
else:
    # Gold table mode: Try DBFS write
    try:
        # Get Run ID from context if available, else generate one
        try:
            context = dbutils.notebook.entry_point.getDbutils().notebook().getContext()
            run_id = str(context.jobId().get()) if context.jobId().isDefined() else str(uuid.uuid4())
        except:
            run_id = str(uuid.uuid4())
            
        print(f"Writing runbook for Run ID: {run_id}")

        # Create directory
        # Handle DBFS path correctly
        if output_path.startswith("dbfs:"):
            local_output_path = output_path.replace("dbfs:", "/dbfs")
        else:
            local_output_path = output_path
            
        final_dir = os.path.join(local_output_path, run_id)
        os.makedirs(final_dir, exist_ok=True)
        
        file_path = os.path.join(final_dir, "runbook.md")
        with open(file_path, "w") as f:
            f.write(markdown_output)
        
        print(f"‚úÖ Runbook successfully written to {file_path}")
        
        # IMPORTANT: Return the runbook content as notebook output
        # This allows retrieval via Jobs API even without DBFS access (Community Edition compatible)
        dbutils.notebook.exit(markdown_output)
        
    except Exception as e:
        print(f"‚ùå Error writing runbook: {e}")
        # Still return the content even if DBFS write fails
        dbutils.notebook.exit(markdown_output)

